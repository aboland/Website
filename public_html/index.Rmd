---
title: "Aidan Boland"
---


<!--For an overview of Latent Dirichlet Allocation click [here](/LDA).  

 Check out an R-Shiny app showing [statistics from the premier league.](http://ff.aboland.ie) -->

<!--![](images/profile.jpg =1000x200)-->
<img src="images/profile.jpg" width="100px" height="20px" />  



I am currently working as a Data Scientist with [Clavis-Insight](http://clavisinsight.com/), a leading firm in eCommerce insights and analytics. My work focuses on researching and implementing statistical techniques to improve processes within the company.

***

### Background

I obtained my PhD from [UCD](http://www.ucd.ie/) under the supervision of [Nial Friel](http://mathsci.ucd.ie/~nial/) (2015). My PhD research focused on overcoming intractable likelihoods in Bayesian analysis. I investigated using Markov Chain Monte Carlo (MCMC) to target tractable approximate posterior distributions which were 'close' to the true posterior distributions for Gibbs random fields. I obtained empirical and theoretical results for a variety of these so called 'noisy' MCMC methods.

I completed a year as a Postdoctoral researcher in the [Insight Center for Data Analytics](https://www.insight-centre.org/) at [UCD](http://www.ucd.ie/) with [Andrew Parnell](http://mathsci.ucd.ie/~parnell_a/) (2016). The project was in conjunction with [Clavis-Insight](http://clavisinsight.com/) and focused on machine learning algorithms, in particular supervised and unsupervised text classification. 


***

### Teaching

I previously lectured an introductory statistical module [(Practical Statistics)](https://sisweb.ucd.ie/usis/w_sm_web_inf_viewer_banner.show_module?p_subj=STAT&p_crse=10050) in [UCD](http://www.ucd.ie/). Topics covered included calculating summary statistics, graphs,  basic probability theory, confidence intervals, [regression and correlation.](http://bayes2.ucd.ie:3838/aboland/STAT10050/) The students were also thought the basics of [Minitab](https://www.minitab.com/en-us/) and [R](https://www.r-project.org/).


I was a tutor in [UCD](http://www.ucd.ie/) from 2010 until 2015. Modules I covered included [Bayesian Statistics](https://sisweb.ucd.ie/usis/w_sm_web_inf_viewer_banner.show_module?p_subj=STAT&p_crse=40390), [Linear Models](https://sisweb.ucd.ie/usis/w_sm_web_inf_viewer_banner.show_module?p_subj=STAT&p_crse=30240) and [Actuarial Statistics](https://sisweb.ucd.ie/usis/w_sm_web_inf_viewer_banner.show_module?p_subj=STAT&p_crse=40160#bookmarkschedule). Each tutorial consisted of up to 30 students at a time. During tutor sessions, students were taken through extra examples  and homework solutions.


***

### Publications

Noisy Monte Carlo: Convergence of Markov chains with approximate transition kernels (2014). [Statistics and Computing.](http://link.springer.com/article/10.1007%2Fs11222-014-9521-x)  

**Abstract**  
*Monte Carlo algorithms often aim to draw from a distribution ππ by simulating a Markov chain with transition kernel $P$ such that $\pi$ is invariant under $P$. However, there are many situations for which it is impractical or impossible to draw from the transition kernel $P$. For instance, this is the case with massive datasets, where is it prohibitively expensive to calculate the likelihood and is also the case for intractable likelihood models arising from, for example, Gibbs random fields, such as those found in spatial statistics and network analysis. A natural approach in these cases is to replace $P$ by an approximation $\hat{P}$. Using theory from the stability of Markov chains we explore a variety of situations where it is possible to quantify how ‘close’ the chain given by the transition kernel $\hat{P}$ is to the chain given by $P$. We apply these results to several examples from spatial statistics and network analysis.*


<!--

<style type = "text/css">
.main-container {
    position:absolute;
  max-width: 940px;
  margin-left: 21%;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}


.leftbar {
    position:absolute;
    max-width: 20%;
    float: left;
    background-color: #e6e6e6;
    padding-top: 10px;
    padding-right: 10px;
    padding-left: 15px;
}

    </style>

<div class="leftbar">
    <br>
    <center>
        <p><img src="images/profile.jpg" width="100px" height="20px" /></p>
    </center>
        <br>
        <p>I am a Postdoctoral researcher in the <a href="https://www.insight-centre.org/">Insight Center for Data Analytics</a> at <a href="http://www.ucd.ie/">UCD</a> with <a href="http://mathsci.ucd.ie/~parnell_a/">Andrew Parnell</a> . My current project is in conjunction with <a href="http://clavisinsight.com/">Clavis-Insight</a> and focuses on machine learning algorithms, in particular supervised and unsupervised classification.</p>
        <br>
    <center>
    <a class="twitter-timeline" href="https://twitter.com/AidoBo" data-widget-id="705121660492488705">Tweets by @AidoBo</a>
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
    </center>
</div>



### Twitter


<a class="twitter-timeline" href="https://twitter.com/AidoBo" data-widget-id="705121660492488705">Tweets by @AidoBo</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>


-->
